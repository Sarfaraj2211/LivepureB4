<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" href="./index.css">
</head>

<body>
    <main>
        <p>This demo is a proof-of-concept solution for this <a href="https://stackoverflow.com/questions/71557879"
                target="_blank" rel="noopener noreferrer">StackOverflow question</a> and <a
                href="https://stackoverflow.com/questions/37404860" target="_blank" rel="noopener noreferrer">also this
                one</a> - as long as you make the required changes<br>i.e. <b>mimeType: "video/mp4; codecs=h264"</b>
            instead of <b>mimeType: "video/webm; codecs=vp9"</b><br>AND<br><b>type: "video/mp4"</b> instead of <b>type:
                "video/webm"</b><br>AND<br><b>result.mp4</b> instead of <b>result.webm</b></p>
        <h2>Click on "Start Webcam" to get started. </h2>
        <h3>
            Core Idea:<br>
            <ol>
                <li>Fetch Webcam Stream via getUserMedia()</li>
                <li>Fetch Screen Share Stream via getDisplayMedia()</li>
                <li>Merge Both Stream using some math & canvas operations</li>
                <li>Use canvas.captureStream() to generate the composite video stream.</li>
                <li>Use AudioContext to merge audio clips (especially needed if using both microphone & system audio).
                </li>
                <li>Use MediaStream constructor to create a new stream using - the video from the new stream + audio
                    from audioContext Destination Node as follows -<br><br>
                    <code>new MediaStream([...newStream.getVideoTracks(), ...audioDestination.stream.getTracks()]);</code>
                </li><br>
                <li>Use newly generated MediaStream as required (i.e. replace in RTCPeerConnection, etc.).</li>
                <li>In this example - MediaRecorder API is used to record the resulting composite/picture-in-picture
                    video. Recording begins when the "Record Resulting Stream" button is clicked. The final result can
                    be downloaded upon clicking the "Stop Recording and Download Resulting Stream" button</li>
            </ol>
        </h3>
        <div id="mediaWrapper"></div>
        <div id="buttonWrapper">
            <button id="startWebcam" title="Start Webcam">Start Webcam</button>
            <button id="startScreenShare" title="Start Screen Share">Start Screen Share</button>
            <button id="mergeStreams" title="Merge Streams">Merge Streams</button>
            <button id="startRecording" title="Record Resulting Stream">Record Resulting Stream</button>
            <button id="stopRecording" title="Stop Recording and Download Resulting Stream">Stop Recording and Download
                Resulting Stream</button>
            <button id="stopAllStreams" title="Stop All Streams">Stop All Streams</button>
        </div>

        <div id="helpText">
            <h1 id="recordingState"></h1><br>
            <h2 id="mutingStreams">
                Note: In a WebRTC setting, you wouldn't be hearing your own voice or the screen share audio via the
                "video" tag. The same has been simulated here by ensuring that all video tags have a "volume = 0".
                Removing this will create a loopback hell which you do not want.<br><br>
                Another way to avoid this issue is to ensure that the video tags are created with ONLY video stream
                tracks using <em style="color: blue;">new MediaStream([ source.getVideoTracks() ])</em> during the
                srcObject assignment.
            </h2>
            <h1>
                Remember to send the correct stream (with both audio and video) to the rest of the peers though.
            </h1>
        </div>
    </main>
</body>
<script src="./index.js"></script>
</html>